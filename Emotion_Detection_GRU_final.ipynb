{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout, SpatialDropout1D\n",
        "\n",
        "# 1. LOAD & CLEAN DATA\n",
        "# New line - Pandas opens zip files automatically!
        "df = pd.read_csv("go_emotions_dataset.zip")\n",
        "df = df.dropna()\n",
        "df = df[df['example_very_unclear'] == False].reset_index(drop=True)\n",
        "\n",
        "# 2. TARGET ENGINEERING\n",
        "# Grouping into 3 Sentiment Classes for Maximum Accuracy\n",
        "positive_emotions = [\n",
        "    'admiration', 'amusement', 'approval', 'caring', 'desire',\n",
        "    'excitement', 'gratitude', 'joy', 'love', 'optimism', 'pride', 'relief'\n",
        "]\n",
        "negative_emotions = [\n",
        "    'anger', 'annoyance', 'disappointment', 'disapproval', 'disgust',\n",
        "    'embarrassment', 'fear', 'grief', 'nervousness', 'remorse', 'sadness'\n",
        "]\n",
        "ambiguous_emotions = [\n",
        "    'confusion', 'curiosity', 'realization', 'surprise'\n",
        "]\n",
        "\n",
        "def get_sentiment(row):\n",
        "    # Priority: Positive > Negative > Neutral/Ambiguous\n",
        "    if any(row[emo] == 1 for emo in positive_emotions):\n",
        "        return 'positive'\n",
        "    elif any(row[emo] == 1 for emo in negative_emotions):\n",
        "        return 'negative'\n",
        "    elif row['neutral'] == 1 or any(row[emo] == 1 for emo in ambiguous_emotions):\n",
        "        return 'neutral'\n",
        "    return 'neutral'\n",
        "\n",
        "df['target'] = df.apply(get_sentiment, axis=1)\n",
        "\n",
        "# 3. TEXT PREPROCESSING\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "df['text_clean'] = df['text'].apply(clean_text)\n",
        "\n",
        "# 4. TOKENIZATION\n",
        "MAX_WORDS = 15000\n",
        "MAX_LEN = 50\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(df['text_clean'])\n",
        "sequences = tokenizer.texts_to_sequences(df['text_clean'])\n",
        "\n",
        "# Masking requires padding 'post'\n",
        "X = pad_sequences(sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "\n",
        "# Encode Labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df['target'])\n",
        "\n",
        "# 5. HANDLE IMBALANCE\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
        "\n",
        "print(\"Class Distribution After Balancing:\")\n",
        "print(pd.Series(y_resampled).value_counts())\n",
        "\n",
        "# 6. TRAIN-TEST SPLIT\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
        ")\n",
        "\n",
        "# 7. BUILD MODEL (Fixed for Accuracy AND Stability)\n",
        "embedding_dim = 100\n",
        "\n",
        "model = Sequential([\n",
        "    # 1. ENABLE MASKING: Critical for accuracy (fixes the 33% issue)\n",
        "    Embedding(MAX_WORDS, embedding_dim, input_length=MAX_LEN, mask_zero=True),\n",
        "\n",
        "    SpatialDropout1D(0.3),\n",
        "\n",
        "    # 2. STABILITY FIX: We use recurrent_dropout=0.2\n",
        "    # This disables the specific CuDNN kernel that was crashing with the mask error.\n",
        "    # It allows the model to handle masked zeros correctly without 'InvalidArgumentError'.\n",
        "    GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
        "    GRU(64, dropout=0.2, recurrent_dropout=0.2),\n",
        "\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 8. TRAIN\n",
        "callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=2,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    callbacks=[callback]\n",
        ")\n",
        "\n",
        "# 9. EVALUATE\n",
        "print(\"\\nModel Evaluation:\")\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Final Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "print(classification_report(y_test, y_pred_classes, target_names=le.classes_))"
      ],
      "metadata": {
        "id": "vcCiVEyzRAah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0624dbc-8e62-4ebc-cc89-da3a925fb435"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution After Balancing:\n",
            "0    20522\n",
            "1    20522\n",
            "2    20522\n",
            "Name: count, dtype: int64\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m770/770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 154ms/step - accuracy: 0.4745 - loss: 1.0040 - val_accuracy: 0.6408 - val_loss: 0.8152\n",
            "Epoch 2/5\n",
            "\u001b[1m770/770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 144ms/step - accuracy: 0.6641 - loss: 0.7813 - val_accuracy: 0.6668 - val_loss: 0.7687\n",
            "Epoch 3/5\n",
            "\u001b[1m770/770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 143ms/step - accuracy: 0.7158 - loss: 0.6893 - val_accuracy: 0.6743 - val_loss: 0.7607\n",
            "Epoch 4/5\n",
            "\u001b[1m770/770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 150ms/step - accuracy: 0.7447 - loss: 0.6259 - val_accuracy: 0.6819 - val_loss: 0.7649\n",
            "Epoch 5/5\n",
            "\u001b[1m770/770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 141ms/step - accuracy: 0.7647 - loss: 0.5795 - val_accuracy: 0.6842 - val_loss: 0.7876\n",
            "\n",
            "Model Evaluation:\n",
            "\u001b[1m385/385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.6805 - loss: 0.7973\n",
            "Final Test Accuracy: 68.42%\n",
            "\u001b[1m385/385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.68      0.84      0.75      4104\n",
            "     neutral       0.64      0.55      0.59      4105\n",
            "    positive       0.73      0.67      0.70      4105\n",
            "\n",
            "    accuracy                           0.68     12314\n",
            "   macro avg       0.68      0.68      0.68     12314\n",
            "weighted avg       0.68      0.68      0.68     12314\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "id": "tb7mtQ2YhiGV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "57027ee4-c185-437e-aa3a-709e408d3e90"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │     \u001b[38;5;34m1,500,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout1d_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m88,320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m37,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,500,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout1d_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">88,320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,889,771\u001b[0m (18.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,889,771</span> (18.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,629,923\u001b[0m (6.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,629,923</span> (6.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m3,259,848\u001b[0m (12.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,259,848</span> (12.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_custom_text(text):\n",
        "    # 1. Clean the text (Use the same function from training)\n",
        "    text_cleaned = clean_text(text)\n",
        "\n",
        "    # 2. Convert to Sequence\n",
        "    sequence = tokenizer.texts_to_sequences([text_cleaned])\n",
        "\n",
        "    # 3. Pad (Critical: Must match training maxlen and padding type)\n",
        "    padded = pad_sequences(sequence, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "\n",
        "    # 4. Predict\n",
        "    prediction = model.predict(padded, verbose=0)\n",
        "\n",
        "    # 5. Decode Label\n",
        "    class_index = np.argmax(prediction)\n",
        "    sentiment = le.inverse_transform([class_index])[0]\n",
        "    confidence = prediction[0][class_index]\n",
        "\n",
        "    print(f\"Text:       {text}\")\n",
        "    print(f\"Sentiment:  {sentiment.upper()}\")\n",
        "    print(f\"Confidence: {confidence*100:.2f}%\\n\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# --- Test with your own examples ---\n",
        "predict_custom_text(\"I absolutely love this, it is amazing!\")\n",
        "predict_custom_text(\"This is the worst experience of my life, I am so angry.\")\n",
        "predict_custom_text(\"The results were confusing and unexpected.\")"
      ],
      "metadata": {
        "id": "tXnddWhlKo72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6203fec-e1cc-4a28-cab5-824c3d275a9e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:       I absolutely love this, it is amazing!\n",
            "Sentiment:  POSITIVE\n",
            "Confidence: 99.78%\n",
            "\n",
            "------------------------------\n",
            "Text:       This is the worst experience of my life, I am so angry.\n",
            "Sentiment:  NEGATIVE\n",
            "Confidence: 90.55%\n",
            "\n",
            "------------------------------\n",
            "Text:       The results were confusing and unexpected.\n",
            "Sentiment:  NEUTRAL\n",
            "Confidence: 58.88%\n",
            "\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# 1. Save the Keras Model\n",
        "model.save('emotion_gru_model.h5')\n",
        "\n",
        "# 2. Save the Tokenizer (Critical for converting text to numbers)\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# 3. Save the Label Encoder (Critical for converting numbers back to text)\n",
        "with open('label_encoder.pickle', 'wb') as handle:\n",
        "    pickle.dump(le, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "print(\"Artifacts saved successfully!\")"
      ],
      "metadata": {
        "id": "j4W7JpcLgpnE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "372ddc7a-65bf-46ba-9840-2c1dbf7cd10d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artifacts saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l-scTYVDkNQB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
